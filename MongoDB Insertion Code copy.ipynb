{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda40b64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !pip3 install -U pymongo\n",
    "# !pip install datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9dedd1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Connect with client\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient('localhost',27017) ## or MongoClient(\"localhost:27\")\n",
    "\n",
    "#Create a data base call \"final5400\"\n",
    "db = client.final5400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b456525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import json\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd58eb",
   "metadata": {},
   "source": [
    "# Stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b046c9c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# stock price data file path \n",
    "file = \"/Users/xianglinlusam/Desktop/5400 Final/dawjones_tenyears2.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aa67d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read the data as json\n",
    "with open(file) as j:\n",
    "    json_data = json.loads(j.read())\n",
    "\n",
    "# The json data is a nested dictionary, therefore, we needed to extract the values of the data\n",
    "# Only extract the values from the json data\n",
    "data = list(json_data.values())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecf35c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize a collection in db called stock_data\n",
    "collection_stock = db.stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a8903",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Insert the json file into the collection\n",
    "collection_stock.insert_many(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3b4a6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#See the list of collection in database. \n",
    "names = db.list_collection_names()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4256640",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Amount of documents in each database\n",
    "print(db.stock_data.count_documents({}))\n",
    "print(db.news_data.count_documents({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586030b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Try query the data using keys \n",
    "query_news = collection_news.find({'ticker': 'AAPL', 'date' : '2022-02-11'})\n",
    "query_stock = collection_stock.find({'ticker': 'AAPL', 'date' : '2022-02-11'})\n",
    "\n",
    "#pprint make it look better. \n",
    "\n",
    "for x in query_news :\n",
    "    print(x)\n",
    "    \n",
    "for x in query_stock:\n",
    "    pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eb8c5f",
   "metadata": {},
   "source": [
    "# News_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdc0f44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Refer to Bengzinga files. \n",
    "\n",
    "# read csv as df, force it into pandas dataframes\n",
    "df = pd.read_csv('/Users/xianglinlusam/Desktop/5400 Final/AAPL_benzinga_2020_to_2023.csv')\n",
    "clean_data = pd.DataFrame(df)\n",
    "\n",
    "# print 'body' column \n",
    "clean_data['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cf73e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# clean news body \n",
    "for i, row in clean_data.iterrows():\n",
    "    html_text = row['body']\n",
    "    parsed_html = BeautifulSoup(html_text, 'html.parser')\n",
    "    text = parsed_html.get_text()\n",
    "    clean_text = re.sub(r'\\s+', ' ', text)\n",
    "    clean_data.at[i, 'body'] = clean_text \n",
    "    \n",
    "print(clean_data['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9b261",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# output the column names \n",
    "print(clean_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19ab3cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print the entire dataframe\n",
    "print(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd67e610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select columns as features\n",
    "new_df = df[['author','updated','title','body','url']]\n",
    "#assign 'AAPL' to new columns, since these are all Apple news data\n",
    "new_df['ticker'] = 'AAPL'\n",
    "# Change the updated column name to date\n",
    "new_df.rename(columns = {'updated':'date'}, inplace = True)\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3048b97d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Change the format of date to year-month-day\n",
    "new_df['date'] = pd.to_datetime(new_df['date']).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1178992",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(new_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a042d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df.to_csv('clean_AAPL.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0112777",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change to dictionary format\n",
    "new_df_dict = new_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b9a799",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write it into json\n",
    "news_json = json.dumps(new_df_dict, indent = 4)\n",
    "\n",
    "# save the file local\n",
    "with open('data.json', 'w') as file:\n",
    "    file.write(news_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e66139e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# path for the saved json file\n",
    "news = '/Users/xianglinlusam/Desktop/5400 Final/data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95e8f16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# open the json file and print it out\n",
    "with open(news) as j_news:\n",
    "    json_news = json.loads(j_news.read())\n",
    "    \n",
    "json_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4096e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add the news data from json into database. \n",
    "collection_news = db.news_data\n",
    "collection_news.insert_many(json_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7051ba",
   "metadata": {},
   "source": [
    "# News_NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610774f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Refer to the spark file\n",
    "\n",
    "# path\n",
    "data_nlp_path = \"/Users/xianglinlusam/Desktop/5400 Final/NLP Data with predicted Stock Price\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071a4a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read data to csv\n",
    "new_data = pd.read_csv(data_nlp_path)\n",
    "\n",
    "# dataframe to dictionary\n",
    "new_data_dict = new_data.to_dict('records')\n",
    "\n",
    "\n",
    "# write into json format then save it locally\n",
    "news_NLP_json = json.dumps(new_data_dict)\n",
    "\n",
    "with open('NLPdata.json', 'w') as file:\n",
    "    file.write(news_NLP_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a9389",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# local path \n",
    "news_NLP = '/Users/xianglinlusam/Desktop/5400 Final/NLPdata.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dca8f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the file, and print it out \n",
    "with open(news_NLP) as j_news:\n",
    "    json_news_nlp = json.loads(j_news.read())\n",
    "    \n",
    "json_news_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b52320",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add the news data into json database\n",
    "collection_news_NLP = db.news_NLP\n",
    "collection_news_NLP.insert_many(json_news_nlp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
